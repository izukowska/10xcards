# OpenRouter Service - Quick Start Guide

## ğŸš€ Quick Setup

### 1. Get API Key
1. Visit [https://openrouter.ai/keys](https://openrouter.ai/keys)
2. Sign up and create an API key
3. Add credits to your account (required for API calls)

### 2. Configure Environment
Create or update `.env` file in project root:

```env
OPENROUTER_API_KEY=sk-or-v1-your-actual-api-key-here
```

**âš ï¸ Security:** Never commit `.env` file to git!

### 3. Test the Service

#### Start Development Server
```bash
npm run dev
```

#### Test Health Check
```bash
curl http://localhost:3000/api/chat
```

Expected response:
```json
{
  "healthy": true,
  "latencyMs": 150
}
```

#### Test Basic Chat
```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Hello!"}
    ]
  }'
```

---

## ğŸ“š Documentation

Detailed documentation available in `.ai/` directory:

- **[openrouter-service-implementation-plan.md](.ai/openrouter-service-implementation-plan.md)** - Full implementation plan
- **[openrouter-usage-examples.md](.ai/openrouter-usage-examples.md)** - Usage examples and API reference
- **[openrouter-env-config.md](.ai/openrouter-env-config.md)** - Environment configuration guide

---

## ğŸ¯ Basic Usage

### In API Routes

```typescript
import { OpenRouterService } from "../../lib/services/openrouter.service";
import { ConsoleLogger } from "../../lib/logger";

const service = new OpenRouterService({
  apiKey: import.meta.env.OPENROUTER_API_KEY,
  logger: new ConsoleLogger(),
});

const response = await service.sendChat({
  messages: [
    { role: "system", content: "You are a helpful assistant." },
    { role: "user", content: "Explain TypeScript in one sentence." }
  ]
});

console.log(response.content);
```

### From Frontend

```typescript
const response = await fetch("/api/chat", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    messages: [
      { role: "user", content: "What is React?" }
    ]
  })
});

const data = await response.json();
console.log(data.content);
```

---

## âœ¨ Key Features

- âœ… **Type-safe** - Full TypeScript support
- âœ… **Error handling** - Comprehensive error scenarios
- âœ… **Retry logic** - Exponential backoff for transient errors
- âœ… **Structured output** - JSON schema validation
- âœ… **Cost control** - Default limits and monitoring
- âœ… **Security** - API key protection and validation
- âœ… **Logging** - Structured logging with request tracking
- âœ… **Testable** - Clean architecture with dependency injection

---

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ types.ts                          # Type definitions
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ logger.ts                     # Logger implementations
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ openrouter.service.ts     # OpenRouter service
â””â”€â”€ pages/
    â””â”€â”€ api/
        â””â”€â”€ chat.ts                   # API endpoint
```

---

## ğŸ” API Endpoints

### POST /api/chat
Send chat messages and get AI response.

**Request:**
```json
{
  "messages": [
    {"role": "user", "content": "Hello"}
  ],
  "model": "openai/gpt-4o-mini",
  "params": {
    "temperature": 0.7,
    "max_tokens": 1000
  }
}
```

**Response:**
```json
{
  "content": "Hello! How can I help you?",
  "model": "openai/gpt-4o-mini",
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 8,
    "total_tokens": 18
  },
  "requestId": "req_123_abc"
}
```

### GET /api/chat
Health check endpoint.

**Response:**
```json
{
  "healthy": true,
  "latencyMs": 150
}
```

---

## ğŸ›¡ï¸ Error Handling

The service handles all error scenarios:

| Error Type | HTTP Status | Retry? | Description |
|------------|-------------|---------|-------------|
| `config` | 500 | âŒ | Missing/invalid configuration |
| `auth` | 401 | âŒ | Invalid API key |
| `rate_limit` | 429 | âœ… | Rate limit exceeded |
| `server` | 503 | âœ… | OpenRouter server error |
| `network` | 503 | âœ… | Network connectivity issue |
| `validation` | 400 | âŒ | Invalid request format |
| `parse` | 500 | âŒ | Invalid response format |
| `timeout` | 504 | âœ… | Request timeout |

---

## ğŸ’° Cost Management

### Default Limits
- **max_tokens:** 1000
- **temperature:** 0.7
- **timeout:** 60s

### Monitor Usage
```typescript
const response = await service.sendChat(options);
console.log(`Tokens used: ${response.usage.total_tokens}`);
```

### Recommended Models
- **Development:** `openai/gpt-4o-mini` (~$0.15 per 1M tokens)
- **Production:** `openai/gpt-4o` (~$5 per 1M tokens)

Check current pricing: [https://openrouter.ai/models](https://openrouter.ai/models)

---

## ğŸ› Troubleshooting

### "OpenRouter API is not configured"
- Ensure `OPENROUTER_API_KEY` is set in `.env`
- Restart dev server after adding env variables

### "Unauthorized" (401)
- Verify API key is valid
- Check you have credits in OpenRouter account

### "Rate limit exceeded" (429)
- Wait a few seconds and retry
- Service automatically retries with backoff

### Health check fails
- Check internet connection
- Verify OpenRouter status: [status.openrouter.ai](https://status.openrouter.ai)

---

## ğŸ“ Next Steps

1. âœ… Service implemented and tested
2. â­ï¸ Integrate with flashcard generation
3. â­ï¸ Add rate limiting per user
4. â­ï¸ Implement response caching
5. â­ï¸ Add usage analytics

---

## ğŸ“„ License

Part of 10xCards project.
